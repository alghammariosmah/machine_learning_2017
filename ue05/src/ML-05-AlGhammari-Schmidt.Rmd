---
title: "ML-05-AlGhammari-Schmidt"
author: "Bernd Schmidt , Osamah Al-Ghammari"
date: "November 03, 2017"
output: pdf_document
---

```{r setup, message=FALSE, results='hide'}
require(plyr)
require(lattice)
require(corrplot)
require(caret)
require(doMC)
registerDoMC(3)
library(zoo)
```

# Gesture Recognition

```{r read data}
filedir <- "../dat"
  
# get all filenames
filenames <- list.files(filedir, full.names = T, pattern="*.csv")

gestures <- list()

gestures$x <- ldply(filenames[1], read.table, sep=',', fill = T, col.names = c('gesture', 'person', 'sample', paste('acc', 1:1000, sep='')))
gestures$y <- ldply(filenames[2], read.table, sep=',', fill = T, col.names = c('gesture', 'person', 'sample', paste('acc', 1:1000, sep='')))
gestures$z <- ldply(filenames[3], read.table, sep=',', fill = T, col.names = c('gesture', 'person', 'sample', paste('acc', 1:1000, sep='')))

```

## Visualization

Currently the samples have different lengths and there are **NA** at the start and/or the end of the sample.

```{r visualize}
matplot(t(gestures$x[1:8,4:1003]), type='l', col=factor(gestures$x[1:8,1]))
```

## Optimization
For optimization, all **NA** values are removed and the values are interpolated to 1000 values per sample.
After that, a rolling median is applied to the sample to smooth it.

```{r optimize}
stepwidth <- 1/1000
optimize <- function(r) {
  row <- r[!is.na(r)] # remove all NA values
  row_approx <- approx(x = seq(0,1,1/(length(row[4:length(row)])-1)), y = row[4:length(row)], xout = seq(0,1,stepwidth), method = 'linear')$y # interpolate
  #row_runmed <- as.numeric(runmed(row_approx, k = 11)) # filter
  rollapply(row_approx, 11, median, na.rm=T)
  #r[,4:1003] <- row_approx[1:1000] # store calcuated values back to row with meta info
  row_approx
}
gestures_opt <- list()
gestures_opt$x <- gestures$x[,1:3]
gestures_opt$y <- gestures$y[,1:3]
gestures_opt$z <- gestures$z[,1:3]
gestures_opt$x[4:1003] <- as.data.frame(t(apply(gestures$x, 1, optimize)
))[1:1000]
gestures_opt$y[4:1003] <- as.data.frame(t(apply(gestures$y, 1, optimize)
))[1:1000]
gestures_opt$z[4:1003] <- as.data.frame(t(apply(gestures$z, 1, optimize)
))[1:1000]
gestures_opt$gesture <- gestures_opt$x[,1]
gestures_opt$data <- gestures_opt$x[,4:1003]
gestures_opt$data[,1001:2000] <- gestures_opt$y[,4:1003]
gestures_opt$data[,2001:3000] <- gestures_opt$z[,4:1003]
matplot(t(gestures_opt$x[1:8,4:1003]), type='l', col=factor(gestures_opt$x[1:8,1]))
```

## Data Validation and Optimization

```{r feature correlation}
gestures_data <- gestures_opt$data
# feature correlation as plot
corrplot(cor(gestures_opt$data[,4:100]), tl.cex = 0.3) # addgrid.col = NA
# remove correlated variable using ?findCorrelation
foundCorIndexes <- findCorrelation(cor(gestures_data))
#foundCorIndexes
corrplot(cor(gestures_data[,-foundCorIndexes]), tl.cex = 0.3)
# remove the features from the data
gestures_opt$data <- gestures_data[,-foundCorIndexes]
```

## Data Partitioning

```{r data_partitioning}
# split into training and test data
set.seed(1704)
indexes_train <- createDataPartition(gestures_opt$gesture, p=0.75, list = F)
indexes_test <- (1:nrow(gestures_opt$data))[-indexes_train]

training <- gestures_opt$data[indexes_train,]
training_gest <- gestures_opt$gesture[indexes_train]
testing <- gestures_opt$data[indexes_test,]
testing_gest <- gestures_opt$gesture[indexes_test]
```

## Feature Selection

```{r feature_selection}
sbfRes <- sbf(x = training, y = training_gest, sbfControl = sbfControl(functions = rfSBF, method = 'repeatedcv', repeats = 5)) # more repeats are better
sbfRes
sbfRes$optVariables
gestures_opt$data <- gestures_opt$data[,sbfRes$optVariables]
```

## Model Training
Now we can use this data to train a model for detecting the gestures

### KNN
```{r model training knn}
models <- list()
models$knn <- train(training,
               factor(training_gest),
               method = 'knn',
               preProcess = c('center', 'scale', 'pca'),
               metric = 'Kappa',
               trControl = trainControl(
                 method = 'LOOCV',
                 preProcOptions = list(thresh = 0.9)
               )
               )
models$knn
varImp(models$knn)
```

```{r predict_test_data knn}
predicted <- predict(models$knn, newdata = testing)

# to ensure, that also when one level is not predicted, the results can be displayed
u = union(predicted, testing_gest)
t = table(factor(predicted, u), factor(testing_gest, u))
conf <- confusionMatrix(t)

levelplot(sweep(conf$table, MARGIN = 2, STATS = colSums(conf$table), FUN = `/`), col.regions = gray(100:0/100))
```

### LDA
To compare the results, now a *lda* model with the same parameters is trained.

```{r model training lda}
models$lda <- train(training,
               factor(training_gest),
               method = 'lda',
               preProcess = c('center', 'scale', 'pca'),
               metric = 'Kappa',
               trControl = trainControl(
                 method = 'LOOCV',
                 preProcOptions = list(thresh = 0.9)
               )
               )
models$lda
```

```{r predict_test_data lda}
predicted <- predict(models$lda, newdata = testing)

# to ensure, that also when one level is not predicted, the results can be displayed
u = union(predicted, testing_gest)
t = table(factor(predicted, u), factor(testing_gest, u))
conf <- confusionMatrix(t)

levelplot(sweep(conf$table, MARGIN = 2, STATS = colSums(conf$table), FUN = `/`), col.regions = gray(100:0/100))
```

### LDA2

```{r model training lda2}
models$lda2 <- train(training,
               factor(training_gest),
               method = 'lda2',
               preProcess = c('center', 'scale', 'pca'),
               metric = 'Kappa',
               trControl = trainControl(
                 method = 'LOOCV',
                 preProcOptions = list(thresh = 0.9)
               )
               )
models$lda2
```

```{r predict_test_data lda2}
predicted <- predict(models$lda2, newdata = testing)

# to ensure, that also when one level is not predicted, the results can be displayed
u = union(predicted, testing$pers)
t = table(factor(predicted, u), factor(testing_gest, u))
conf <- confusionMatrix(t)

levelplot(sweep(conf$table, MARGIN = 2, STATS = colSums(conf$table), FUN = `/`), col.regions = gray(100:0/100))
```